{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4319a670",
   "metadata": {},
   "source": [
    "# Lab 5 Wide and Deep Networks\n",
    "\n",
    "\n",
    "## Team member\n",
    "Rongwei Ji, Jonathan Mejia, Xiaoqing Zou\n",
    "\n",
    "## Data introduction\n",
    "US Census Demographic Data Data source: https://www.kaggle.com/datasets/muonneutrino/us-census-demographic-data/data\n",
    "\n",
    "## Assigenment requriement:\n",
    "You will need to convert this from regression to four levels of classification by quantizing the variable of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041b639",
   "metadata": {},
   "source": [
    "[1 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). You have the option of using tf.dataset for processing, but it is not required. \n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af68f858",
   "metadata": {},
   "source": [
    "The mushroom dataset contains categorical variables describing various features of mushrooms, along with a target variable indicating whether the mushroom is edible or poisonous. The following chart below goes more in depth of on each variable and the relationship of each value representing their description."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8367826b",
   "metadata": {},
   "source": [
    "The data is organized as follows:\n",
    "\n",
    "|Variable | description|\n",
    "|------|---------|\n",
    "|cap-shape:          |      bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n",
    "|cap-surface:        |      fibrous=f,grooves=g,scaly=y,smooth=s\n",
    "|cap-color:          |      brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y\n",
    "|bruises:           |      bruises=t,no=f\n",
    "|odor:               |      almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\n",
    "|gill-attachment:     |     attached=a,descending=d,free=f,notched=n\n",
    "|gill-spacing:        |     close=c,crowded=w,distant=d\n",
    "|gill-size:           |     broad=b,narrow=n\n",
    "|gill-color:          |     black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y\n",
    "|stalk-shape:         |     enlarging=e,tapering=t\n",
    "|stalk-root:          |     bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?\n",
    "|stalk-surface-above-ring:| fibrous=f,scaly=y,silky=k,smooth=s\n",
    "|stalk-surface-below-ring:| fibrous=f,scaly=y,silky=k,smooth=s\n",
    "|stalk-color-above-ring: |  brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n",
    "|stalk-color-below-ring: |  brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n",
    "|veil-type:           |     partial=p,universal=u\n",
    "|veil-color:          |     brown=n,orange=o,white=w,yellow=y\n",
    "|ring-number:         |     none=n,one=o,two=t\n",
    "|ring-type:           |     cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z\n",
    "|spore-print-color:   |     black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y\n",
    "|population:          |    abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y\n",
    "|habitat:             |     grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d\n",
    "|**class (target):** |     p = Poisonous, e = Edible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3e55cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5644, 23)\n",
      "(5644, 121)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5644, 122)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# gathers data from CSV file\n",
    "mushrooms = pd.read_csv('mushrooms.csv')\n",
    "\n",
    "mushrooms.replace(to_replace='?', value=np.nan, inplace = True)\n",
    "mushrooms.dropna(inplace=True)\n",
    "mushrooms.reset_index()\n",
    "\n",
    "print(mushrooms.shape)\n",
    "\n",
    "# Define columns for cross-product features\n",
    "columns_to_cross = [['cap-shape', 'cap-color'], ['odor', 'bruises'], ['gill-color', 'stalk-surface-above-ring']]\n",
    "\n",
    "# Create cross-product features\n",
    "for columns in columns_to_cross:\n",
    "    new_feature_name = '_'.join(columns)\n",
    "    mushrooms[new_feature_name] = mushrooms[columns[0]].astype(str) + '_' + mushrooms[columns[1]].astype(str)\n",
    "\n",
    "# Drop original features used for cross-product\n",
    "mushrooms.drop(columns=[col for sublist in columns_to_cross for col in sublist], inplace=True)\n",
    "\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "mushrooms_encoded = pd.get_dummies(mushrooms.drop(columns='class'))\n",
    "print(mushrooms_encoded.shape)\n",
    "# Target variable\n",
    "if mushrooms['class'].dtype=='object':\n",
    "    # encode the label of target as an integer\n",
    "    tmp = LabelEncoder()\n",
    "    mushrooms['class'] = tmp.fit_transform(mushrooms['class'])\n",
    "\n",
    "# Describe final dataset\n",
    "final_dataset = mushrooms_encoded.join(mushrooms['class'])\n",
    "\n",
    "final_dataset.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4e002c",
   "metadata": {},
   "source": [
    "[1 points] Identify groups of features in your data that should be combined into cross-product features. Provide a compelling justification for why these features should be crossed (or why some features should not be crossed). \n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a046b84c",
   "metadata": {},
   "source": [
    "In the mushroom dataset, there are several groups of features that could be combined into cross-product features. However, it's important to consider the nature of the features and whether combining them would result in meaningful interactions. Here are some potential groups of features and their justifications for being crossed or not:\n",
    "\n",
    "## Cap Features (Cap Shape, Cap Surface, Cap Color):\n",
    "\n",
    "Justification for crossing: These features describe different aspects of the mushroom cap. Cross-producting them might capture interactions between the shape, surface, and color of the cap, potentially revealing patterns specific to certain combinations that could be indicative of edibility or toxicity.\n",
    "\n",
    "Justification against crossing: While these features describe aspects of the mushroom cap, their individual characteristics might be more informative than their interactions. For example, a specific cap color or shape might be more strongly associated with toxicity regardless of the surface texture.\n",
    "\n",
    "\n",
    "## Gill Features (Gill Attachment, Gill Spacing, Gill Size, Gill Color):\n",
    "\n",
    "Justification for crossing: These features pertain to the gills, which play a crucial role in spore production and distribution. Combining them could reveal how different combinations of gill characteristics influence the toxicity of mushrooms.\n",
    "\n",
    "Justification against crossing: Gill characteristics might already capture sufficient information individually, and combining them into cross-products could lead to a high-dimensional feature space without significant improvement in predictive performance.\n",
    "\n",
    "\n",
    "## Stalk Features (Stalk Shape, Stalk Root, Stalk Surface Above/Below Ring, Stalk Color Above/Below Ring):\n",
    "\n",
    "Justification for crossing: Stalk features describe various attributes of the mushroom stalk, and their interactions might provide insights into the overall structure and health of the mushroom. Certain combinations might be indicative of specific species or toxicity levels.\n",
    "\n",
    "Justification against crossing: Stalk features might be diverse enough on their own to capture relevant information about the mushroom. Cross-producting them could introduce noise or create overly complex interactions that are difficult to interpret.\n",
    "\n",
    "\n",
    "## Ring Features (Veil Type, Veil Color, Ring Number, Ring Type):\n",
    "\n",
    "Justification for crossing: Ring features relate to structures like the veil and ring on the mushroom, which can vary significantly between species. Combining them might reveal associations between different aspects of these structures and the mushroom's toxicity.\n",
    "\n",
    "Justification against crossing: These features might not interact in ways that significantly impact the mushroom's toxicity. Each feature could independently contribute valuable information without the need for cross-products.\n",
    "\n",
    "\n",
    "Ultimately, the decision to cross certain features depends on domain knowledge, experimentation, and the specific goals of the analysis. While some interactions may enhance predictive power, others may not provide meaningful insights or could even introduce noise into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b812d1b0",
   "metadata": {},
   "source": [
    "[1 points] Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dfe6c1",
   "metadata": {},
   "source": [
    "A more suitable metric for evaluating the algorithm's performance on imbalanced datasets like this one is the F1 score, specifically the weighted average of the F1 score for each class. The F1 score considers both precision and recall, making it a robust metric for evaluating classification performance, especially when there is class imbalance.\n",
    "\n",
    "Here's why the F1 score is appropriate for this task:\n",
    "\n",
    "Consideration of Precision and Recall: The F1 score balances precision and recall, which are crucial in binary classification tasks like identifying edible and poisonous mushrooms. Precision measures the proportion of true positive predictions among all positive predictions, while recall measures the proportion of true positive predictions among all actual positive instances. Both precision and recall provide valuable insights into the model's performance.\n",
    "\n",
    "Handling Imbalanced Data: Since the mushroom dataset likely contains imbalanced classes (i.e., more edible mushrooms than poisonous ones or vice versa), the F1 score accounts for this imbalance by considering both false positives and false negatives. It provides a more accurate assessment of the model's ability to correctly classify instances from both classes.\n",
    "\n",
    "Business Relevance: Misclassifying a poisonous mushroom as edible (false negative) can have severe consequences, potentially leading to health risks or even fatalities. Similarly, misclassifying an edible mushroom as poisonous (false positive) can result in unnecessary waste or loss. Therefore, it's essential to strike a balance between minimizing false negatives and false positives, which the F1 score addresses effectively.\n",
    "\n",
    "Interpretability: The F1 score is easy to interpret and communicate, making it suitable for explaining the model's performance to stakeholders or decision-makers who may not be familiar with technical details of machine learning.\n",
    "\n",
    "In summary, the F1 score is a suitable metric for evaluating the algorithm's performance on the mushroom dataset due to its consideration of precision, recall, handling of imbalanced data, relevance to the business case, and interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bec4bc",
   "metadata": {},
   "source": [
    "[1 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Argue why your cross validation method is a realistic mirroring of how an algorithm would be used in practice. Use the method to split your data that you argue for. \n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113be791",
   "metadata": {},
   "source": [
    "For dividing the data into training and testing sets, I would recommend using stratified k-fold cross-validation, specifically with k=5 or k=10. Here's why this method is appropriate:\n",
    "\n",
    "Handling Imbalanced Data: Since the mushroom dataset likely contains imbalanced classes (i.e., more edible mushrooms than poisonous ones or vice versa), stratified k-fold cross-validation ensures that each fold preserves the same class distribution as the original dataset. This helps prevent bias in model evaluation and ensures that the model's performance is representative across all classes.\n",
    "\n",
    "Robustness: Cross-validation provides a more robust estimate of model performance compared to a single train-test split. It reduces the variability in performance metrics that can arise from random variations in the training and testing data splits.\n",
    "\n",
    "Realistic Reflection of Model Deployment: Stratified k-fold cross-validation simulates how the model would generalize to unseen data in practice. It iteratively trains the model on different subsets of the data and evaluates its performance on independent validation sets. This process mimics how the model would be deployed in real-world scenarios where it encounters new, unseen instances.\n",
    "\n",
    "Now, let's use stratified k-fold cross-validation to split the mushroom dataset into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d5b0b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5644\n",
      "Training set size: 4516\n",
      "Testing set size: 1128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Features and target\n",
    "X = mushrooms_encoded\n",
    "y = mushrooms['class']\n",
    "\n",
    "print(y.size)\n",
    "\n",
    "# Initialize StratifiedKFold with k=5\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Output the sizes of training and testing sets for validation\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Testing set size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ab0f8",
   "metadata": {},
   "source": [
    "This code snippet divides the data into five stratified folds while shuffling the data to ensure randomness. It then outputs the sizes of the resulting training and testing sets. Using stratified k-fold cross-validation provides a realistic estimation of the model's performance on unseen data while mitigating issues related to class imbalance and variability in model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c1569",
   "metadata": {},
   "source": [
    "[2 points] Create at least three combined wide and deep networks to classify your data using Keras (this total of \"three\" includes the model you will train in the next step of the rubric). Visualize the performance of the network on the training data and validation data in the same plot versus the training iterations. Note: you can use the \"history\" return parameter that is part of Keras \"fit\" function to easily access this data.\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a031301a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['AUTOGRAPH_VERBOSITY'] = '0'\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "\n",
    "\n",
    "# Define input dimension\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# Define combined wide and deep network\n",
    "# Adam adjust Adaptive Learning Rates\n",
    "\n",
    "def create_wide_deep_network_1():\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    wide_layer = Dense(32, activation='relu')(input_layer)\n",
    "    hidden_layer1 = Dense(64, activation='relu')(input_layer)\n",
    "    hidden_layer2 = Dense(32, activation='relu')(hidden_layer1)\n",
    "    hidden_layer3 = Dense(16, activation='relu')(input_layer)\n",
    "    hidden_layer4 = Dense(8, activation='relu')(hidden_layer1)\n",
    "    concat_layer = Concatenate()([wide_layer, hidden_layer2])\n",
    "    output_layer = Dense(1, activation='sigmoid')(concat_layer)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "\n",
    "def create_wide_deep_network_2():\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    wide_layer = Dense(32, activation='relu')(input_layer)\n",
    "    hidden_layer1 = Dense(64, activation='relu')(input_layer)\n",
    "    hidden_layer2 = Dense(32, activation='relu')(hidden_layer1)\n",
    "    hidden_layer3 = Dense(16, activation='relu')(input_layer)\n",
    "    hidden_layer4 = Dense(8, activation='relu')(hidden_layer1)\n",
    "    concat_layer = Concatenate()([wide_layer, hidden_layer2])\n",
    "    output_layer = Dense(1, activation='sigmoid')(concat_layer)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# RMS prop\n",
    "\n",
    "def create_wide_deep_network_3():\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    wide_layer = Dense(32, activation='relu')(input_layer)\n",
    "    hidden_layer1 = Dense(64, activation='relu')(input_layer)\n",
    "    hidden_layer2 = Dense(32, activation='relu')(hidden_layer1)\n",
    "    hidden_layer3 = Dense(16, activation='relu')(input_layer)\n",
    "    hidden_layer4 = Dense(8, activation='relu')(hidden_layer1)\n",
    "    concat_layer = Concatenate()([wide_layer, hidden_layer2])\n",
    "    output_layer = Dense(1, activation='sigmoid')(concat_layer)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='RMSprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Create and train combined wide and deep network\n",
    "model = create_wide_deep_network_1()\n",
    "wide_deep_history_1 = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=98, verbose=0)\n",
    "\n",
    "# Create and train combined wide and deep network\n",
    "wide_deep_model_2 = create_wide_deep_network_2()\n",
    "wide_deep_history_2 = wide_deep_model_2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=98, verbose=0)\n",
    "\n",
    "# Create and train combined wide and deep network\n",
    "wide_deep_model_3 = create_wide_deep_network_3()\n",
    "wide_deep_history_3 = wide_deep_model_3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=98, verbose=0)\n",
    "\n",
    "\n",
    "# Visualize performance\n",
    "plt.plot(wide_deep_history_1.history['accuracy'], label='ADAM Training Accuracy 1')\n",
    "plt.plot(wide_deep_history_1.history['val_accuracy'], label='ADAM Validation Accuracy 1')\n",
    "plt.plot(wide_deep_history_2.history['accuracy'], label='SGD Training Accuracy 2')\n",
    "plt.plot(wide_deep_history_2.history['val_accuracy'], label='SGD Validation Accuracy 2')\n",
    "plt.plot(wide_deep_history_3.history['accuracy'], label='RMSprop Training Accuracy 3')\n",
    "plt.plot(wide_deep_history_3.history['val_accuracy'], label='RMSprop Validation Accuracy 3')\n",
    "\n",
    "plt.title('Model Performance')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train combined wide and deep network\n",
    "model = create_wide_deep_network_1()\n",
    "wide_deep_history_1 = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=20, verbose=0)\n",
    "\n",
    "# Create and train combined wide and deep network\n",
    "wide_deep_model_2 = create_wide_deep_network_2()\n",
    "wide_deep_history_2 = wide_deep_model_2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=20, verbose=0)\n",
    "\n",
    "# Create and train combined wide and deep network\n",
    "wide_deep_model_3 = create_wide_deep_network_3()\n",
    "wide_deep_history_3 = wide_deep_model_3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=20, verbose=0)\n",
    "\n",
    "\n",
    "# Visualize performance\n",
    "plt.plot(wide_deep_history_1.history['accuracy'], label='ADAM Training Accuracy 1')\n",
    "plt.plot(wide_deep_history_1.history['val_accuracy'], label='ADAM Validation Accuracy 1')\n",
    "plt.plot(wide_deep_history_2.history['accuracy'], label='SGD Training Accuracy 2')\n",
    "plt.plot(wide_deep_history_2.history['val_accuracy'], label='SGD Validation Accuracy 2')\n",
    "plt.plot(wide_deep_history_3.history['accuracy'], label='RMSprop Training Accuracy 3')\n",
    "plt.plot(wide_deep_history_3.history['val_accuracy'], label='RMSprop Validation Accuracy 3')\n",
    "\n",
    "plt.title('Model Performance')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70503aa5",
   "metadata": {},
   "source": [
    "[2 points] Investigate generalization performance by altering the number of layers in the deep branch of the network. Try at least two models (this \"two\" includes the wide and deep model trained from the previous step). Use the method of cross validation and evaluation metric that you argued for at the beginning of the lab to answer: What model with what number of layers performs superiorly? Use proper statistical methods to compare the performance of different models.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82e72ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# now lets see how well the model performed\n",
    "from sklearn import metrics as mt\n",
    "yhat_proba_1 = model.predict(X_test) # sigmoid output probabilities\n",
    "yhat_1 = np.round(yhat_proba_1) # round to get binary class\n",
    "yhat_proba_2 = wide_deep_model_2.predict(X_test) # sigmoid output probabilities\n",
    "yhat_2 = np.round(yhat_proba_2) # round to get binary class\n",
    "yhat_proba_3 = wide_deep_model_3.predict(X_test) # sigmoid output probabilities\n",
    "yhat_3 = np.round(yhat_proba_3) # round to get binary class\n",
    "#Unable to diplay matrix\n",
    "#print(mt.confusion_matrix(y_test,yhat_1))\n",
    "print(\"\\nOptimizer Used: Adam Optimizer\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(mt.classification_report(y_test,yhat_1))\n",
    "#print(mt.confusion_matrix(y_test,yhat_2))\n",
    "print(\"\\nOptimizer Used: Stochastic Gradient Descent Optimizer\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(mt.classification_report(y_test,yhat_2))\n",
    "#print(mt.confusion_matrix(y_test,yhat_3))\n",
    "print(\"\\nOptimizer Used: RMSprop\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(mt.classification_report(y_test,yhat_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a22131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate F1 score for each model\n",
    "f1_score_1 = f1_score(y_test, yhat_1)\n",
    "f1_score_2 = f1_score(y_test, yhat_2)\n",
    "f1_score_3 = f1_score(y_test, yhat_3)\n",
    "\n",
    "# Print F1 scores\n",
    "print(\"F1 Score - Adam Model:\", f1_score_1)\n",
    "print(\"F1 Score - Stochastic Gradient Descent Model:\", f1_score_2)\n",
    "print(\"F1 Score - RMSprop Model:\", f1_score_3)\n",
    "\n",
    "# F1 scores for each model\n",
    "f1_scores = [f1_score_1, f1_score_2, f1_score_3]\n",
    "models = ['Adam Model', 'Stochastic Gradient Descent Model', 'RMSprop Model']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(models, f1_scores, color='skyblue')\n",
    "plt.xlabel('Model Name')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score Comparison of Different Models')\n",
    "plt.ylim(0, 1)  # Set y-axis limits to 0 and 1 for F1 score\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2efcd4",
   "metadata": {},
   "source": [
    "[1 points] Compare the performance of your best wide and deep network to a standard multi-layer perceptron (MLP). Alternatively, you can compare to a network without the wide branch (i.e., just the deep network). For classification tasks, compare using the receiver operating characteristic and area under the curve. For regression tasks, use Bland-Altman plots and residual variance calculations.  Use proper statistical methods to compare the performance of different models.  \n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62052b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MLP \n",
    "# these values have been hand tuned\n",
    "# sigmoid with SGD, batching, nesterov's momentum, \n",
    "# L2, adaptive learning rate\n",
    "def create_mlp():\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(50,), \n",
    "                    activation='logistic', # compare to sigmoid\n",
    "                    solver='sgd', \n",
    "                    alpha=10, # L2 penalty\n",
    "                    batch_size=98, # min of 98, num_samples\n",
    "                    learning_rate='adaptive', # decrease rate if loss goes up\n",
    "                    learning_rate_init=0.1, # only SGD\n",
    "                    power_t=0.5,    # only SGD with inverse scaling\n",
    "                    max_iter=20, \n",
    "                    shuffle=True, \n",
    "                    random_state=1, \n",
    "                    tol=1e-9, # for stopping\n",
    "                    verbose=False, \n",
    "                    momentum=.3, # only SGD\n",
    "                    nesterovs_momentum=True, # only SGD\n",
    "                    early_stopping=False, \n",
    "                    validation_fraction=0.1, # only if early_stop is true\n",
    "                    beta_1=0.9, # adam decay rate of moment\n",
    "                    beta_2=0.999, # adam decay rate of moment\n",
    "                    epsilon=1e-08) # adam numerical stabilizer\n",
    "    return clf\n",
    "\n",
    "%time \n",
    "\n",
    "# Create and train combined wide and deep network\n",
    "mlp = create_mlp()\n",
    "# Fit the best wide and deep network\n",
    "mlp = mlp.fit(X_train,y_train)\n",
    "# Predict probabilities for the best wide and deep network\n",
    "y_pred_proba_mlp = mlp.predict_proba(X_test)[:, 1]\n",
    "# Compute ROC curve and AUC for wide and deep network\n",
    "fpr_mlp, tpr_mlp, _ = roc_curve(y_test, y_pred_proba_mlp)\n",
    "roc_auc_mlp = auc(fpr_mlp, tpr_mlp)\n",
    "\n",
    "fpr_adam, tpr_adam, _ = roc_curve(y_test, yhat_1)\n",
    "roc_auc_adam = auc(fpr_adam, tpr_adam)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_mlp, tpr_mlp, color='blue', lw=2, label='MLP (AUC = %0.2f)' % roc_auc_mlp)\n",
    "plt.plot(fpr_mlp, tpr_mlp, color='red', lw=2, label='ADAM (AUC = %0.2f)' % roc_auc_adam)\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be29c8",
   "metadata": {},
   "source": [
    "Exceptional Work (1 points total)\n",
    "----\n",
    "5000 students: You have free reign to provide additional analyses.\n",
    "----\n",
    "One idea (required for 7000 level students): Capture the embedding weights from the deep network and (if needed) perform dimensionality reduction on the output of these embedding layers (only if needed). That is, pass the observations into the network, save the embedded weights (called embeddings), and then perform  dimensionality reduction in order to visualize results. Visualize and explain any clusters in the data.\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d73d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "embedding_model = Model(inputs=model.input, outputs=model.get_layer('concatenate_3').output)  # Assuming 'dense_3' is the layer before concatenation\n",
    "embeddings = embedding_model.predict(X_train)\n",
    "\n",
    "# Step 5: Perform Dimensionality Reduction (if needed)\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_pca = pca.fit_transform(embeddings)\n",
    "\n",
    "# Step 6: Visualize the Embeddings\n",
    "plt.scatter(embeddings_pca[:,0], embeddings_pca[:,1], c=y_train, cmap='viridis')\n",
    "plt.title('PCA Visualization of Embeddings')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(label='Class')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbde430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
